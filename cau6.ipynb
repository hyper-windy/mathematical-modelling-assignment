{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BTL_MHH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL0GyedJsRpw"
      },
      "source": [
        "#**Bài 6 của mô hình hóa toán học (Sử dụng tensor flow 1.9.0)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h9kLnigIh5K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "d889a544-2726-4dbe-f57c-2b9e0cc532d9"
      },
      "source": [
        "pip install tensorflow==1.9.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/95/274190b39950e1e9eef4b071acefea832ac3e2c19bb4b442fa54f3214d2e/tensorflow-1.9.0-cp36-cp36m-manylinux1_x86_64.whl (51.1MB)\n",
            "\u001b[K     |████████████████████████████████| 51.1MB 87kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0) (0.36.2)\n",
            "Collecting setuptools<=39.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 40.6MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.10.0,>=1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/1f/3da43860db614e294a034e42d4be5c8f7f0d2c75dc1c428c541116d8cdab/tensorboard-1.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0) (0.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0) (3.4.0)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement setuptools>=41.2, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-auth 1.17.2 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: setuptools, tensorboard, tensorflow\n",
            "  Found existing installation: setuptools 51.1.1\n",
            "    Uninstalling setuptools-51.1.1:\n",
            "      Successfully uninstalled setuptools-51.1.1\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed setuptools-39.1.0 tensorboard-1.9.0 tensorflow-1.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9djULMa_AcmV",
        "outputId": "0d2ab75e-07ae-4c50-e747-e122bcf0c0ed"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "#-------------------- [KHOI TAO] -------------------------#\r\n",
        "# Nhap so diem du lieu:\r\n",
        "N = 100\r\n",
        "\r\n",
        "#Nhap step muon train vao dayyyy:\r\n",
        "trainStep = 10000\r\n",
        "\r\n",
        "# Nhap so node cua hidden layer muon train:\r\n",
        "n_node = 100\r\n",
        "\r\n",
        "# Nhap pt y' - f(x,y)\r\n",
        "def func(dy_dx, x, y):\r\n",
        "  lq = (1+3*(x**2))/(1+x+x**3)\r\n",
        "  return dy_dx + (x + lq)*y - x**3 - 2*x - lq*x*x\r\n",
        "\r\n",
        "# Nhap dieu kien ban dau y(x_k) = y_k\r\n",
        "k = 0\r\n",
        "y_k = 1\r\n",
        "#----------------------------------------------------------#\r\n",
        "\r\n",
        "#Tao N diem trong doan [0,2] (Train data)\r\n",
        "x_train = np.linspace(0,2,N,endpoint=True)    \r\n",
        "# Copy x_train vao x_t de tinh toan\r\n",
        "x_t      = np.zeros((len(x_train),1))\r\n",
        "x_t[:,0] = x_train\r\n",
        "\r\n",
        "\r\n",
        "#Nghiem chinh xac de so sanh: y = e^(-0.5.x^2)/(1 + x + x^3) + x^2\r\n",
        "def func_y(x):\r\n",
        "  return np.exp(-0.5*x**2)/(1+x+x**3)+x**2\r\n",
        "\r\n",
        "# Target data\r\n",
        "y_train = func_y(x_train)\r\n",
        "\r\n",
        "\r\n",
        "#------------------------ [KHOI TAO NEURAL NETWORK] ----------------------#\r\n",
        "# khoi tao Input [N,1]\r\n",
        "x1 = tf.placeholder(\"float\", [None,1 ]) \r\n",
        "\r\n",
        "# hidden layer: Sigmoid (n_node units)\r\n",
        "W1 = tf.Variable(tf.zeros([1, n_node])) \r\n",
        "b1 = tf.Variable(tf.zeros([n_node]))\r\n",
        "# Output cua hidden layer: y1 = sigmoid(x1.w + b) [N, n_node]\r\n",
        "y1 = tf.nn.sigmoid(tf.matmul(x1, W1)+b1)\r\n",
        "\r\n",
        "# Output layer: linear (y1.W1) (1 units)\r\n",
        "W2 = tf.Variable(tf.zeros([n_node, 1]))\r\n",
        "\r\n",
        "# Network output [N,1]\r\n",
        "y = tf.matmul(y1, W2)\r\n",
        "\r\n",
        "# Tinh dao ham dy/dx\r\n",
        "dif = tf.matmul(tf.multiply(y1*(1-y1),W1),W2) \r\n",
        "#---------------------------------------------------------------------------#\r\n",
        "\r\n",
        "t_loss = (func(dif, x1, y))**2\r\n",
        "\r\n",
        "\r\n",
        "# Tinh loss function: (y' - f(x,y))^2 + (y(x0) - y0)^2\r\n",
        "loss = tf.reduce_mean(t_loss) + (y[k] - y_k)**2\r\n",
        "\r\n",
        "# Optimize\r\n",
        "train_step = tf.train.AdamOptimizer(1e-2).minimize(loss)\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "sess = tf.InteractiveSession()\r\n",
        "sess.run(init)\r\n",
        "\r\n",
        "# Bat dau training  !!!\r\n",
        "for i in range(trainStep):  \r\n",
        "    sess.run(train_step,feed_dict={x1: x_t})\r\n",
        "    if i%50 == 0:\r\n",
        "        total_loss = sess.run(loss,feed_dict={x1: x_t})\r\n",
        "        #In loss va in y0 de theo doi nha !!!\r\n",
        "        print(\"Step {}:\".format(i))\r\n",
        "        print(\"loss = {}\".format(total_loss))\r\n",
        "        print(\"y0 = {}\".format(sess.run(y[k], feed_dict={x1: x_t})))\r\n",
        "        print(\"--------------------------------------------------\")\r\n",
        "\r\n",
        "# Luu model !!!\r\n",
        "saver = tf.train.Saver(max_to_keep=1)\r\n",
        "saver.save(sess,'Model cua Nhom/Phong.ckpt',global_step=trainStep)\r\n",
        "saver = tf.train.Saver(max_to_keep=1)\r\n",
        "\r\n",
        "# Lay model ra xai\r\n",
        "model_file=\"Model cua Nhom/Phong.ckpt-\" + str(trainStep)\r\n",
        "saver.restore(sess, model_file)\r\n",
        "\r\n",
        "#Day la output !!!\r\n",
        "output = sess.run(y,feed_dict={x1:x_t})\r\n",
        "\r\n",
        "# Khoi tao y_output co chieu bang x_train\r\n",
        "y_output = x_train.copy()\r\n",
        "\r\n",
        "for i in range(len(x_train)):\r\n",
        "    y_output[i] = output[i]\r\n",
        "\r\n",
        "# Ve bieu do:\r\n",
        "plt.plot(x_train,y_train, 'r')\r\n",
        "plt.plot(x_train,y_output, 'b')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0:\n",
            "loss = [42.623085]\n",
            "y0 = [0.4999999]\n",
            "--------------------------------------------------\n",
            "Step 50:\n",
            "loss = [10.299842]\n",
            "y0 = [2.2524116]\n",
            "--------------------------------------------------\n",
            "Step 100:\n",
            "loss = [8.413577]\n",
            "y0 = [1.9360638]\n",
            "--------------------------------------------------\n",
            "Step 150:\n",
            "loss = [7.3424425]\n",
            "y0 = [1.7042699]\n",
            "--------------------------------------------------\n",
            "Step 200:\n",
            "loss = [6.3528037]\n",
            "y0 = [1.4945216]\n",
            "--------------------------------------------------\n",
            "Step 250:\n",
            "loss = [5.3379645]\n",
            "y0 = [1.2965664]\n",
            "--------------------------------------------------\n",
            "Step 300:\n",
            "loss = [4.339679]\n",
            "y0 = [1.1128229]\n",
            "--------------------------------------------------\n",
            "Step 350:\n",
            "loss = [3.4313807]\n",
            "y0 = [0.9485504]\n",
            "--------------------------------------------------\n",
            "Step 400:\n",
            "loss = [2.6663878]\n",
            "y0 = [0.80776626]\n",
            "--------------------------------------------------\n",
            "Step 450:\n",
            "loss = [2.062593]\n",
            "y0 = [0.69173354]\n",
            "--------------------------------------------------\n",
            "Step 500:\n",
            "loss = [1.6098515]\n",
            "y0 = [0.59896505]\n",
            "--------------------------------------------------\n",
            "Step 550:\n",
            "loss = [1.2835615]\n",
            "y0 = [0.5263048]\n",
            "--------------------------------------------------\n",
            "Step 600:\n",
            "loss = [1.0555044]\n",
            "y0 = [0.47011542]\n",
            "--------------------------------------------------\n",
            "Step 650:\n",
            "loss = [0.89990914]\n",
            "y0 = [0.42701635]\n",
            "--------------------------------------------------\n",
            "Step 700:\n",
            "loss = [0.7957894]\n",
            "y0 = [0.39417383]\n",
            "--------------------------------------------------\n",
            "Step 750:\n",
            "loss = [0.7271912]\n",
            "y0 = [0.36933717]\n",
            "--------------------------------------------------\n",
            "Step 800:\n",
            "loss = [0.6825219]\n",
            "y0 = [0.35075983]\n",
            "--------------------------------------------------\n",
            "Step 850:\n",
            "loss = [0.65362966]\n",
            "y0 = [0.3370978]\n",
            "--------------------------------------------------\n",
            "Step 900:\n",
            "loss = [0.63493335]\n",
            "y0 = [0.3273121]\n",
            "--------------------------------------------------\n",
            "Step 950:\n",
            "loss = [0.62270266]\n",
            "y0 = [0.32058942]\n",
            "--------------------------------------------------\n",
            "Step 1000:\n",
            "loss = [0.61450005]\n",
            "y0 = [0.31628326]\n",
            "--------------------------------------------------\n",
            "Step 1050:\n",
            "loss = [0.60877204]\n",
            "y0 = [0.3138702]\n",
            "--------------------------------------------------\n",
            "Step 1100:\n",
            "loss = [0.604554]\n",
            "y0 = [0.31291914]\n",
            "--------------------------------------------------\n",
            "Step 1150:\n",
            "loss = [0.6012623]\n",
            "y0 = [0.31307244]\n",
            "--------------------------------------------------\n",
            "Step 1200:\n",
            "loss = [0.59855384]\n",
            "y0 = [0.31403276]\n",
            "--------------------------------------------------\n",
            "Step 1250:\n",
            "loss = [0.59623146]\n",
            "y0 = [0.31555593]\n",
            "--------------------------------------------------\n",
            "Step 1300:\n",
            "loss = [0.5941817]\n",
            "y0 = [0.31744573]\n",
            "--------------------------------------------------\n",
            "Step 1350:\n",
            "loss = [0.5923389]\n",
            "y0 = [0.31954873]\n",
            "--------------------------------------------------\n",
            "Step 1400:\n",
            "loss = [0.59066314]\n",
            "y0 = [0.321751]\n",
            "--------------------------------------------------\n",
            "Step 1450:\n",
            "loss = [0.589128]\n",
            "y0 = [0.32397056]\n",
            "--------------------------------------------------\n",
            "Step 1500:\n",
            "loss = [0.5877141]\n",
            "y0 = [0.3261536]\n",
            "--------------------------------------------------\n",
            "Step 1550:\n",
            "loss = [0.58640623]\n",
            "y0 = [0.32826808]\n",
            "--------------------------------------------------\n",
            "Step 1600:\n",
            "loss = [0.5851921]\n",
            "y0 = [0.33029595]\n",
            "--------------------------------------------------\n",
            "Step 1650:\n",
            "loss = [0.58406085]\n",
            "y0 = [0.33223185]\n",
            "--------------------------------------------------\n",
            "Step 1700:\n",
            "loss = [0.5830039]\n",
            "y0 = [0.33407497]\n",
            "--------------------------------------------------\n",
            "Step 1750:\n",
            "loss = [0.58201337]\n",
            "y0 = [0.33582985]\n",
            "--------------------------------------------------\n",
            "Step 1800:\n",
            "loss = [0.5810827]\n",
            "y0 = [0.337502]\n",
            "--------------------------------------------------\n",
            "Step 1850:\n",
            "loss = [0.580206]\n",
            "y0 = [0.33909798]\n",
            "--------------------------------------------------\n",
            "Step 1900:\n",
            "loss = [0.57937837]\n",
            "y0 = [0.34062394]\n",
            "--------------------------------------------------\n",
            "Step 1950:\n",
            "loss = [0.5785954]\n",
            "y0 = [0.34208596]\n",
            "--------------------------------------------------\n",
            "Step 2000:\n",
            "loss = [0.5778532]\n",
            "y0 = [0.34348953]\n",
            "--------------------------------------------------\n",
            "Step 2050:\n",
            "loss = [0.5771482]\n",
            "y0 = [0.3448391]\n",
            "--------------------------------------------------\n",
            "Step 2100:\n",
            "loss = [0.5764777]\n",
            "y0 = [0.34613875]\n",
            "--------------------------------------------------\n",
            "Step 2150:\n",
            "loss = [0.57583845]\n",
            "y0 = [0.34739253]\n",
            "--------------------------------------------------\n",
            "Step 2200:\n",
            "loss = [0.5752285]\n",
            "y0 = [0.34860346]\n",
            "--------------------------------------------------\n",
            "Step 2250:\n",
            "loss = [0.57464564]\n",
            "y0 = [0.34977475]\n",
            "--------------------------------------------------\n",
            "Step 2300:\n",
            "loss = [0.57408786]\n",
            "y0 = [0.35090867]\n",
            "--------------------------------------------------\n",
            "Step 2350:\n",
            "loss = [0.5735533]\n",
            "y0 = [0.35200775]\n",
            "--------------------------------------------------\n",
            "Step 2400:\n",
            "loss = [0.5730406]\n",
            "y0 = [0.35307395]\n",
            "--------------------------------------------------\n",
            "Step 2450:\n",
            "loss = [0.57254785]\n",
            "y0 = [0.35410973]\n",
            "--------------------------------------------------\n",
            "Step 2500:\n",
            "loss = [0.57207423]\n",
            "y0 = [0.35511652]\n",
            "--------------------------------------------------\n",
            "Step 2550:\n",
            "loss = [0.5716182]\n",
            "y0 = [0.356096]\n",
            "--------------------------------------------------\n",
            "Step 2600:\n",
            "loss = [0.5711787]\n",
            "y0 = [0.35704967]\n",
            "--------------------------------------------------\n",
            "Step 2650:\n",
            "loss = [0.57075465]\n",
            "y0 = [0.35797903]\n",
            "--------------------------------------------------\n",
            "Step 2700:\n",
            "loss = [0.5703451]\n",
            "y0 = [0.3588846]\n",
            "--------------------------------------------------\n",
            "Step 2750:\n",
            "loss = [0.56994873]\n",
            "y0 = [0.3597686]\n",
            "--------------------------------------------------\n",
            "Step 2800:\n",
            "loss = [0.56956434]\n",
            "y0 = [0.3606322]\n",
            "--------------------------------------------------\n",
            "Step 2850:\n",
            "loss = [0.5691899]\n",
            "y0 = [0.36147714]\n",
            "--------------------------------------------------\n",
            "Step 2900:\n",
            "loss = [0.5688235]\n",
            "y0 = [0.36230436]\n",
            "--------------------------------------------------\n",
            "Step 2950:\n",
            "loss = [0.56846076]\n",
            "y0 = [0.36311653]\n",
            "--------------------------------------------------\n",
            "Step 3000:\n",
            "loss = [0.56809497]\n",
            "y0 = [0.36391875]\n",
            "--------------------------------------------------\n",
            "Step 3050:\n",
            "loss = [0.5677139]\n",
            "y0 = [0.36471775]\n",
            "--------------------------------------------------\n",
            "Step 3100:\n",
            "loss = [0.56729525]\n",
            "y0 = [0.3655268]\n",
            "--------------------------------------------------\n",
            "Step 3150:\n",
            "loss = [0.56679714]\n",
            "y0 = [0.3663738]\n",
            "--------------------------------------------------\n",
            "Step 3200:\n",
            "loss = [0.566144]\n",
            "y0 = [0.3673146]\n",
            "--------------------------------------------------\n",
            "Step 3250:\n",
            "loss = [0.565195]\n",
            "y0 = [0.3684635]\n",
            "--------------------------------------------------\n",
            "Step 3300:\n",
            "loss = [0.5636853]\n",
            "y0 = [0.37005547]\n",
            "--------------------------------------------------\n",
            "Step 3350:\n",
            "loss = [0.56105626]\n",
            "y0 = [0.37260577]\n",
            "--------------------------------------------------\n",
            "Step 3400:\n",
            "loss = [0.5558576]\n",
            "y0 = [0.37742043]\n",
            "--------------------------------------------------\n",
            "Step 3450:\n",
            "loss = [0.54271245]\n",
            "y0 = [0.38920665]\n",
            "--------------------------------------------------\n",
            "Step 3500:\n",
            "loss = [0.48441428]\n",
            "y0 = [0.44084677]\n",
            "--------------------------------------------------\n",
            "Step 3550:\n",
            "loss = [0.10112915]\n",
            "y0 = [0.953619]\n",
            "--------------------------------------------------\n",
            "Step 3600:\n",
            "loss = [0.03699786]\n",
            "y0 = [1.0192921]\n",
            "--------------------------------------------------\n",
            "Step 3650:\n",
            "loss = [0.02991125]\n",
            "y0 = [1.0173434]\n",
            "--------------------------------------------------\n",
            "Step 3700:\n",
            "loss = [0.02809452]\n",
            "y0 = [1.0144924]\n",
            "--------------------------------------------------\n",
            "Step 3750:\n",
            "loss = [0.0271424]\n",
            "y0 = [1.0128943]\n",
            "--------------------------------------------------\n",
            "Step 3800:\n",
            "loss = [0.02631671]\n",
            "y0 = [1.011998]\n",
            "--------------------------------------------------\n",
            "Step 3850:\n",
            "loss = [0.02546871]\n",
            "y0 = [1.0114496]\n",
            "--------------------------------------------------\n",
            "Step 3900:\n",
            "loss = [0.024563]\n",
            "y0 = [1.011054]\n",
            "--------------------------------------------------\n",
            "Step 3950:\n",
            "loss = [0.02358688]\n",
            "y0 = [1.0107104]\n",
            "--------------------------------------------------\n",
            "Step 4000:\n",
            "loss = [0.02253166]\n",
            "y0 = [1.0103669]\n",
            "--------------------------------------------------\n",
            "Step 4050:\n",
            "loss = [0.02138924]\n",
            "y0 = [1.0099977]\n",
            "--------------------------------------------------\n",
            "Step 4100:\n",
            "loss = [0.02015108]\n",
            "y0 = [1.0095862]\n",
            "--------------------------------------------------\n",
            "Step 4150:\n",
            "loss = [0.01880922]\n",
            "y0 = [1.0091217]\n",
            "--------------------------------------------------\n",
            "Step 4200:\n",
            "loss = [0.01735631]\n",
            "y0 = [1.0085948]\n",
            "--------------------------------------------------\n",
            "Step 4250:\n",
            "loss = [0.01578839]\n",
            "y0 = [1.0079974]\n",
            "--------------------------------------------------\n",
            "Step 4300:\n",
            "loss = [0.01410667]\n",
            "y0 = [1.0073235]\n",
            "--------------------------------------------------\n",
            "Step 4350:\n",
            "loss = [0.01232299]\n",
            "y0 = [1.0065708]\n",
            "--------------------------------------------------\n",
            "Step 4400:\n",
            "loss = [0.01046626]\n",
            "y0 = [1.0057443]\n",
            "--------------------------------------------------\n",
            "Step 4450:\n",
            "loss = [0.00859119]\n",
            "y0 = [1.0048606]\n",
            "--------------------------------------------------\n",
            "Step 4500:\n",
            "loss = [0.00678412]\n",
            "y0 = [1.003953]\n",
            "--------------------------------------------------\n",
            "Step 4550:\n",
            "loss = [0.00515838]\n",
            "y0 = [1.0030705]\n",
            "--------------------------------------------------\n",
            "Step 4600:\n",
            "loss = [0.00382651]\n",
            "y0 = [1.0022699]\n",
            "--------------------------------------------------\n",
            "Step 4650:\n",
            "loss = [0.00285375]\n",
            "y0 = [1.0015969]\n",
            "--------------------------------------------------\n",
            "Step 4700:\n",
            "loss = [0.00222586]\n",
            "y0 = [1.0010711]\n",
            "--------------------------------------------------\n",
            "Step 4750:\n",
            "loss = [0.0018649]\n",
            "y0 = [1.0006846]\n",
            "--------------------------------------------------\n",
            "Step 4800:\n",
            "loss = [0.00167645]\n",
            "y0 = [1.0004123]\n",
            "--------------------------------------------------\n",
            "Step 4850:\n",
            "loss = [0.00158515]\n",
            "y0 = [1.0002266]\n",
            "--------------------------------------------------\n",
            "Step 4900:\n",
            "loss = [0.00154332]\n",
            "y0 = [1.0001029]\n",
            "--------------------------------------------------\n",
            "Step 4950:\n",
            "loss = [0.00152491]\n",
            "y0 = [1.0000224]\n",
            "--------------------------------------------------\n",
            "Step 5000:\n",
            "loss = [0.00151702]\n",
            "y0 = [0.99997157]\n",
            "--------------------------------------------------\n",
            "Step 5050:\n",
            "loss = [0.00151363]\n",
            "y0 = [0.99994105]\n",
            "--------------------------------------------------\n",
            "Step 5100:\n",
            "loss = [0.00151211]\n",
            "y0 = [0.99992365]\n",
            "--------------------------------------------------\n",
            "Step 5150:\n",
            "loss = [0.00151136]\n",
            "y0 = [0.9999147]\n",
            "--------------------------------------------------\n",
            "Step 5200:\n",
            "loss = [0.00151091]\n",
            "y0 = [0.99991107]\n",
            "--------------------------------------------------\n",
            "Step 5250:\n",
            "loss = [0.00151057]\n",
            "y0 = [0.9999106]\n",
            "--------------------------------------------------\n",
            "Step 5300:\n",
            "loss = [0.00151028]\n",
            "y0 = [0.9999123]\n",
            "--------------------------------------------------\n",
            "Step 5350:\n",
            "loss = [0.00151004]\n",
            "y0 = [0.99991524]\n",
            "--------------------------------------------------\n",
            "Step 5400:\n",
            "loss = [0.0015098]\n",
            "y0 = [0.9999186]\n",
            "--------------------------------------------------\n",
            "Step 5450:\n",
            "loss = [0.00150959]\n",
            "y0 = [0.99992263]\n",
            "--------------------------------------------------\n",
            "Step 5500:\n",
            "loss = [0.00150939]\n",
            "y0 = [0.99992657]\n",
            "--------------------------------------------------\n",
            "Step 5550:\n",
            "loss = [0.00150922]\n",
            "y0 = [0.99993044]\n",
            "--------------------------------------------------\n",
            "Step 5600:\n",
            "loss = [0.00150904]\n",
            "y0 = [0.99993443]\n",
            "--------------------------------------------------\n",
            "Step 5650:\n",
            "loss = [0.00150889]\n",
            "y0 = [0.99993855]\n",
            "--------------------------------------------------\n",
            "Step 5700:\n",
            "loss = [0.00150875]\n",
            "y0 = [0.99994224]\n",
            "--------------------------------------------------\n",
            "Step 5750:\n",
            "loss = [0.00150861]\n",
            "y0 = [0.9999459]\n",
            "--------------------------------------------------\n",
            "Step 5800:\n",
            "loss = [0.00150848]\n",
            "y0 = [0.9999497]\n",
            "--------------------------------------------------\n",
            "Step 5850:\n",
            "loss = [0.00150836]\n",
            "y0 = [0.9999531]\n",
            "--------------------------------------------------\n",
            "Step 5900:\n",
            "loss = [0.00150827]\n",
            "y0 = [0.99995655]\n",
            "--------------------------------------------------\n",
            "Step 5950:\n",
            "loss = [0.00150817]\n",
            "y0 = [0.9999597]\n",
            "--------------------------------------------------\n",
            "Step 6000:\n",
            "loss = [0.0015081]\n",
            "y0 = [0.9999629]\n",
            "--------------------------------------------------\n",
            "Step 6050:\n",
            "loss = [0.00150802]\n",
            "y0 = [0.9999664]\n",
            "--------------------------------------------------\n",
            "Step 6100:\n",
            "loss = [0.00150794]\n",
            "y0 = [0.99996877]\n",
            "--------------------------------------------------\n",
            "Step 6150:\n",
            "loss = [0.00150786]\n",
            "y0 = [0.9999724]\n",
            "--------------------------------------------------\n",
            "Step 6200:\n",
            "loss = [0.00160761]\n",
            "y0 = [0.9998207]\n",
            "--------------------------------------------------\n",
            "Step 6250:\n",
            "loss = [0.00151949]\n",
            "y0 = [0.9999255]\n",
            "--------------------------------------------------\n",
            "Step 6300:\n",
            "loss = [0.00150792]\n",
            "y0 = [0.99999154]\n",
            "--------------------------------------------------\n",
            "Step 6350:\n",
            "loss = [0.00150778]\n",
            "y0 = [0.9999862]\n",
            "--------------------------------------------------\n",
            "Step 6400:\n",
            "loss = [0.00150977]\n",
            "y0 = [0.99994576]\n",
            "--------------------------------------------------\n",
            "Step 6450:\n",
            "loss = [0.00184129]\n",
            "y0 = [1.0005783]\n",
            "--------------------------------------------------\n",
            "Step 6500:\n",
            "loss = [0.00150957]\n",
            "y0 = [1.0000468]\n",
            "--------------------------------------------------\n",
            "Step 6550:\n",
            "loss = [0.0015079]\n",
            "y0 = [1.0000043]\n",
            "--------------------------------------------------\n",
            "Step 6600:\n",
            "loss = [0.00150772]\n",
            "y0 = [0.9999932]\n",
            "--------------------------------------------------\n",
            "Step 6650:\n",
            "loss = [0.01482528]\n",
            "y0 = [1.0032189]\n",
            "--------------------------------------------------\n",
            "Step 6700:\n",
            "loss = [0.0015118]\n",
            "y0 = [1.0000478]\n",
            "--------------------------------------------------\n",
            "Step 6750:\n",
            "loss = [0.00150865]\n",
            "y0 = [1.0000356]\n",
            "--------------------------------------------------\n",
            "Step 6800:\n",
            "loss = [0.00150797]\n",
            "y0 = [1.0000087]\n",
            "--------------------------------------------------\n",
            "Step 6850:\n",
            "loss = [0.00150777]\n",
            "y0 = [0.9999971]\n",
            "--------------------------------------------------\n",
            "Step 6900:\n",
            "loss = [0.01558047]\n",
            "y0 = [1.0033703]\n",
            "--------------------------------------------------\n",
            "Step 6950:\n",
            "loss = [0.00160645]\n",
            "y0 = [0.9998125]\n",
            "--------------------------------------------------\n",
            "Step 7000:\n",
            "loss = [0.00150931]\n",
            "y0 = [1.000038]\n",
            "--------------------------------------------------\n",
            "Step 7050:\n",
            "loss = [0.00150825]\n",
            "y0 = [1.000018]\n",
            "--------------------------------------------------\n",
            "Step 7100:\n",
            "loss = [0.0015079]\n",
            "y0 = [1.000002]\n",
            "--------------------------------------------------\n",
            "Step 7150:\n",
            "loss = [0.00150786]\n",
            "y0 = [1.0000031]\n",
            "--------------------------------------------------\n",
            "Step 7200:\n",
            "loss = [0.00260703]\n",
            "y0 = [0.999166]\n",
            "--------------------------------------------------\n",
            "Step 7250:\n",
            "loss = [0.00151984]\n",
            "y0 = [1.00001]\n",
            "--------------------------------------------------\n",
            "Step 7300:\n",
            "loss = [0.00150923]\n",
            "y0 = [1.0000441]\n",
            "--------------------------------------------------\n",
            "Step 7350:\n",
            "loss = [0.00150835]\n",
            "y0 = [1.0000122]\n",
            "--------------------------------------------------\n",
            "Step 7400:\n",
            "loss = [0.00150802]\n",
            "y0 = [0.9999989]\n",
            "--------------------------------------------------\n",
            "Step 7450:\n",
            "loss = [0.00150807]\n",
            "y0 = [0.9999792]\n",
            "--------------------------------------------------\n",
            "Step 7500:\n",
            "loss = [0.00199471]\n",
            "y0 = [0.9994414]\n",
            "--------------------------------------------------\n",
            "Step 7550:\n",
            "loss = [0.00151081]\n",
            "y0 = [1.0000762]\n",
            "--------------------------------------------------\n",
            "Step 7600:\n",
            "loss = [0.00150905]\n",
            "y0 = [1.0000399]\n",
            "--------------------------------------------------\n",
            "Step 7650:\n",
            "loss = [0.00150831]\n",
            "y0 = [1.0000097]\n",
            "--------------------------------------------------\n",
            "Step 7700:\n",
            "loss = [0.00150801]\n",
            "y0 = [0.99999726]\n",
            "--------------------------------------------------\n",
            "Step 7750:\n",
            "loss = [0.01075433]\n",
            "y0 = [1.0028635]\n",
            "--------------------------------------------------\n",
            "Step 7800:\n",
            "loss = [0.00154511]\n",
            "y0 = [1.0002661]\n",
            "--------------------------------------------------\n",
            "Step 7850:\n",
            "loss = [0.0015099]\n",
            "y0 = [1.0000548]\n",
            "--------------------------------------------------\n",
            "Step 7900:\n",
            "loss = [0.00150876]\n",
            "y0 = [1.0000185]\n",
            "--------------------------------------------------\n",
            "Step 7950:\n",
            "loss = [0.00150826]\n",
            "y0 = [1.0000014]\n",
            "--------------------------------------------------\n",
            "Step 8000:\n",
            "loss = [0.00150867]\n",
            "y0 = [1.0000176]\n",
            "--------------------------------------------------\n",
            "Step 8050:\n",
            "loss = [0.00184187]\n",
            "y0 = [0.9995352]\n",
            "--------------------------------------------------\n",
            "Step 8100:\n",
            "loss = [0.00151349]\n",
            "y0 = [1.0001255]\n",
            "--------------------------------------------------\n",
            "Step 8150:\n",
            "loss = [0.00150919]\n",
            "y0 = [1.0000257]\n",
            "--------------------------------------------------\n",
            "Step 8200:\n",
            "loss = [0.00150847]\n",
            "y0 = [1.0000088]\n",
            "--------------------------------------------------\n",
            "Step 8250:\n",
            "loss = [0.00150824]\n",
            "y0 = [1.0000068]\n",
            "--------------------------------------------------\n",
            "Step 8300:\n",
            "loss = [0.00230933]\n",
            "y0 = [0.9992171]\n",
            "--------------------------------------------------\n",
            "Step 8350:\n",
            "loss = [0.00152197]\n",
            "y0 = [1.0001774]\n",
            "--------------------------------------------------\n",
            "Step 8400:\n",
            "loss = [0.00150927]\n",
            "y0 = [1.000024]\n",
            "--------------------------------------------------\n",
            "Step 8450:\n",
            "loss = [0.0015085]\n",
            "y0 = [1.0000095]\n",
            "--------------------------------------------------\n",
            "Step 8500:\n",
            "loss = [0.00150827]\n",
            "y0 = [0.99998903]\n",
            "--------------------------------------------------\n",
            "Step 8550:\n",
            "loss = [0.00239071]\n",
            "y0 = [0.999188]\n",
            "--------------------------------------------------\n",
            "Step 8600:\n",
            "loss = [0.00151944]\n",
            "y0 = [1.0000112]\n",
            "--------------------------------------------------\n",
            "Step 8650:\n",
            "loss = [0.00150966]\n",
            "y0 = [1.0000303]\n",
            "--------------------------------------------------\n",
            "Step 8700:\n",
            "loss = [0.00150876]\n",
            "y0 = [1.0000097]\n",
            "--------------------------------------------------\n",
            "Step 8750:\n",
            "loss = [0.00150833]\n",
            "y0 = [0.99999964]\n",
            "--------------------------------------------------\n",
            "Step 8800:\n",
            "loss = [0.00251739]\n",
            "y0 = [1.0009288]\n",
            "--------------------------------------------------\n",
            "Step 8850:\n",
            "loss = [0.00168939]\n",
            "y0 = [1.0004839]\n",
            "--------------------------------------------------\n",
            "Step 8900:\n",
            "loss = [0.00151122]\n",
            "y0 = [1.0000486]\n",
            "--------------------------------------------------\n",
            "Step 8950:\n",
            "loss = [0.00150926]\n",
            "y0 = [1.0000216]\n",
            "--------------------------------------------------\n",
            "Step 9000:\n",
            "loss = [0.00150862]\n",
            "y0 = [1.0000051]\n",
            "--------------------------------------------------\n",
            "Step 9050:\n",
            "loss = [0.00150825]\n",
            "y0 = [0.9999961]\n",
            "--------------------------------------------------\n",
            "Step 9100:\n",
            "loss = [0.00509574]\n",
            "y0 = [0.99829835]\n",
            "--------------------------------------------------\n",
            "Step 9150:\n",
            "loss = [0.00151265]\n",
            "y0 = [1.0001192]\n",
            "--------------------------------------------------\n",
            "Step 9200:\n",
            "loss = [0.00150971]\n",
            "y0 = [1.000047]\n",
            "--------------------------------------------------\n",
            "Step 9250:\n",
            "loss = [0.00150878]\n",
            "y0 = [1.0000129]\n",
            "--------------------------------------------------\n",
            "Step 9300:\n",
            "loss = [0.00150835]\n",
            "y0 = [1.0000025]\n",
            "--------------------------------------------------\n",
            "Step 9350:\n",
            "loss = [0.00427474]\n",
            "y0 = [1.0016065]\n",
            "--------------------------------------------------\n",
            "Step 9400:\n",
            "loss = [0.00155873]\n",
            "y0 = [1.0003034]\n",
            "--------------------------------------------------\n",
            "Step 9450:\n",
            "loss = [0.0015104]\n",
            "y0 = [1.0000665]\n",
            "--------------------------------------------------\n",
            "Step 9500:\n",
            "loss = [0.00150901]\n",
            "y0 = [1.0000141]\n",
            "--------------------------------------------------\n",
            "Step 9550:\n",
            "loss = [0.00150847]\n",
            "y0 = [1.000004]\n",
            "--------------------------------------------------\n",
            "Step 9600:\n",
            "loss = [0.00150895]\n",
            "y0 = [0.9999742]\n",
            "--------------------------------------------------\n",
            "Step 9650:\n",
            "loss = [0.00219799]\n",
            "y0 = [0.99931824]\n",
            "--------------------------------------------------\n",
            "Step 9700:\n",
            "loss = [0.00151785]\n",
            "y0 = [1.0000246]\n",
            "--------------------------------------------------\n",
            "Step 9750:\n",
            "loss = [0.00150994]\n",
            "y0 = [1.000036]\n",
            "--------------------------------------------------\n",
            "Step 9800:\n",
            "loss = [0.00150903]\n",
            "y0 = [1.0000085]\n",
            "--------------------------------------------------\n",
            "Step 9850:\n",
            "loss = [0.00150851]\n",
            "y0 = [1.0000029]\n",
            "--------------------------------------------------\n",
            "Step 9900:\n",
            "loss = [0.00150849]\n",
            "y0 = [1.0000185]\n",
            "--------------------------------------------------\n",
            "Step 9950:\n",
            "loss = [0.0018064]\n",
            "y0 = [1.0005562]\n",
            "--------------------------------------------------\n",
            "INFO:tensorflow:Restoring parameters from Model cua Nhom/Phong.ckpt-10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCTBz75AMQYr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}